{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "8omuWV4IuyeE"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "#@markdown Enter the URL of the YouTube video, or the path to the video/audio file you want to transcribe, give the output path, etc. and run the cell. HTML file embeds the video for YouTube, and audio for media files.\n",
        "\n",
        "Source = 'File' #@param ['Youtube', 'File']\n",
        "#@markdown ---\n",
        "#@markdown #### **Youtube video**\n",
        "video_url = \"https://www.youtube.com/watch?v=S4wWClQhZaA\" #@param {type:\"string\"}\n",
        "#store_audio = True #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "#@markdown #### **Google Drive video or audio path (mp4, wav, mp3)**\n",
        "video_path = \"/Users/saichandrapandraju/transcribe/input.mp3\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "output_path = \"./transcript_doc_patient/\" #@param {type:\"string\"}\n",
        "output_path = str(Path(output_path))\n",
        "#@markdown ---\n",
        "#@markdown #### **Title for transcription of media file**\n",
        "audio_title = \"Sample_Transcript\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown #### Copy a token from your [Hugging Face tokens page](https://huggingface.co/settings/tokens) and paste it below.\n",
        "access_token = \"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\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change the video.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NvDON2GxZpIb"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vgK82ahXNje",
        "outputId": "de308338-4de1-4c32-d8cf-1f55cdfc9472"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/saichandrapandraju/transcribe/transcript_doc_patient\n"
          ]
        }
      ],
      "source": [
        "Path(output_path).mkdir(parents=True, exist_ok=True)\n",
        "%cd {output_path}\n",
        "video_title = \"\"\n",
        "video_id = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-a6pLioVHjl"
      },
      "source": [
        "## From YouTube"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ct4adIANpQvX"
      },
      "source": [
        " Installing [`yt-dlp`](https://github.com/yt-dlp/yt-dlp) and downloading the [video](https://youtu.be/NSp2fEQ6wyA) from youtube."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL7fC4aZdpyH",
        "outputId": "fe476495-9fd4-4a0c-ee99-385b699547ba"
      },
      "outputs": [],
      "source": [
        "if Source == \"Youtube\":\n",
        "  !pip install -U yt-dlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI5sr2GI4gXb"
      },
      "source": [
        "Custom build of `ffmpeg` as [recommended](https://github.com/yt-dlp/yt-dlp#strongly-recommended) by `yt-dlp`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KsedMPN-daEX"
      },
      "outputs": [],
      "source": [
        "if Source == \"Youtube\":\n",
        "  !wget -O - -q  https://github.com/yt-dlp/FFmpeg-Builds/releases/download/latest/ffmpeg-master-latest-linux64-gpl.tar.xz | xz -qdc| tar -x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNcD7tx9UmyK",
        "outputId": "5d939c8a-2675-4d76-a90d-e183534eb20b"
      },
      "outputs": [],
      "source": [
        "#Getting video info\n",
        "if Source == \"Youtube\":\n",
        "  from yt_dlp import YoutubeDL\n",
        "  with YoutubeDL() as ydl:\n",
        "    info_dict = ydl.extract_info(video_url, download=False)\n",
        "    video_title = info_dict.get('title', None)\n",
        "    video_id = info_dict.get('id', None)\n",
        "    print(\"Title: \" + video_title) # <= Here, you got the video title\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_UyK49aPNiD"
      },
      "source": [
        "Downloading the audio from YouTube."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VHzpv72dkvV",
        "outputId": "6bd876df-cdaa-4d0d-cf2a-92ac692fba88"
      },
      "outputs": [],
      "source": [
        "if Source == \"Youtube\":\n",
        "  !yt-dlp -xv --ffmpeg-location ffmpeg-master-latest-linux64-gpl/bin --audio-format wav  -o \"{str(output_path) + '/'}input.wav\" -- {video_url}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJRyeo5RVYb8"
      },
      "source": [
        "## or from File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VjORT6CkVoTF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
            "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
            "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_3 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
            "  libavutil      58. 29.100 / 58. 29.100\n",
            "  libavcodec     60. 31.102 / 60. 31.102\n",
            "  libavformat    60. 16.100 / 60. 16.100\n",
            "  libavdevice    60.  3.100 / 60.  3.100\n",
            "  libavfilter     9. 12.100 /  9. 12.100\n",
            "  libswscale      7.  5.100 /  7.  5.100\n",
            "  libswresample   4. 12.100 /  4. 12.100\n",
            "  libpostproc    57.  3.100 / 57.  3.100\n",
            "Input #0, mp3, from '/Users/saichandrapandraju/transcribe/input.mp3':\n",
            "  Metadata:\n",
            "    encoder         : Lavf60.21.101\n",
            "  Duration: 00:05:13.22, start: 0.023021, bitrate: 81 kb/s\n",
            "  Stream #0:0: Audio: mp3, 48000 Hz, stereo, fltp, 81 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc60.40\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, wav, to 'input.wav':\n",
            "  Metadata:\n",
            "    ISFT            : Lavf60.16.100\n",
            "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc60.31.102 pcm_s16le\n",
            "\u001b[1;35m[out#0/wav @ 0x14c005500] \u001b[0mvideo:0kB audio:9787kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000778%\n",
            "size=    9787kB time=00:05:13.17 bitrate= 256.0kbits/s speed= 569x    \n"
          ]
        }
      ],
      "source": [
        "if Source == 'File':\n",
        "    !ffmpeg -i {repr(video_path)} -vn -acodec pcm_s16le -ar 16000 -ac 1 -y input.wav"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1u1vbqd_VzNp"
      },
      "source": [
        "## Prepending a spacer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7qMLTISFE6M"
      },
      "source": [
        "`pyannote.audio` seems to miss the first 0.5 seconds of the audio, and, therefore, we prepend a spcacer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaRDsBV1CWi8",
        "outputId": "e8e543a0-aada-47d5-9aaa-0cc14cc529ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_io.BufferedRandom name='input_prep.wav'>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "spacermilli = 2000\n",
        "spacer = AudioSegment.silent(duration=spacermilli)\n",
        "\n",
        "\n",
        "audio = AudioSegment.from_wav(\"input.wav\")\n",
        "\n",
        "audio = spacer.append(audio, crossfade=0)\n",
        "\n",
        "audio.export('input_prep.wav', format='wav')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PhJssCTv-i3"
      },
      "source": [
        "## PyAnnotate Diarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-18cLfHOwrEP",
        "outputId": "434d4b53-794a-4f8f-e75e-1efe80506732"
      },
      "outputs": [],
      "source": [
        "from pyannote.audio import Pipeline\n",
        "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.0\", use_auth_token= (access_token) or True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "eiiHtC6WxAOD"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<pyannote.audio.pipelines.speaker_diarization.SpeakerDiarization at 0x2bb841180>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "pipeline.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "w-Jthpijx5tn"
      },
      "outputs": [],
      "source": [
        "DEMO_FILE = {'uri': 'blabla', 'audio': 'input_prep.wav'}\n",
        "dz = pipeline(DEMO_FILE, num_speakers=2)\n",
        "\n",
        "with open(\"diarization.txt\", \"w\") as text_file:\n",
        "    text_file.write(str(dz))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'SPEAKER_01'"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc_ = next(dz.itertracks(yield_label=True))[-1]\n",
        "doc_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "if doc_ == \"SPEAKER_00\":\n",
        "    speakers_ = {\"SPEAKER_00\": \"Doctor\", \"SPEAKER_01\": \"Patient\"}\n",
        "else:\n",
        "    speakers_ = {\"SPEAKER_00\": \"Patient\", \"SPEAKER_01\": \"Doctor\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "lsNoS35lx_We"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(<Segment(16.3413, 18.2258)>, 1, 'SPEAKER_01')\n",
            "(<Segment(17.3769, 19.8048)>, 0, 'SPEAKER_00')\n",
            "(<Segment(20.0594, 22.708)>, 1, 'SPEAKER_01')\n",
            "(<Segment(23.0815, 25.1358)>, 0, 'SPEAKER_00')\n",
            "(<Segment(25.8489, 26.545)>, 1, 'SPEAKER_01')\n",
            "(<Segment(26.8336, 29.4143)>, 1, 'SPEAKER_01')\n",
            "(<Segment(30.2632, 34.8132)>, 0, 'SPEAKER_00')\n",
            "(<Segment(35.017, 35.034)>, 0, 'SPEAKER_00')\n",
            "(<Segment(35.0509, 37.2071)>, 0, 'SPEAKER_00')\n",
            "(<Segment(38.2598, 41.2649)>, 0, 'SPEAKER_00')\n"
          ]
        }
      ],
      "source": [
        "print(*list(dz.itertracks(yield_label = True))[:10], sep=\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wp36eMedRkR0"
      },
      "source": [
        "# Preparing audio files according to the diarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "KPGOaVpOH7pZ"
      },
      "outputs": [],
      "source": [
        "def millisec(timeStr):\n",
        "  spl = timeStr.split(\":\")\n",
        "  s = (int)((int(spl[0]) * 60 * 60 + int(spl[1]) * 60 + float(spl[2]) )* 1000)\n",
        "  return s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Co3BIIH6aW4"
      },
      "source": [
        "Grouping the diarization segments according to the speaker."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "umQdzNFzcP2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['[ 00:00:16.341 -->  00:00:18.225] 1 SPEAKER_01']\n",
            "['[ 00:00:17.376 -->  00:00:19.804] 0 SPEAKER_00']\n",
            "['[ 00:00:20.059 -->  00:00:22.707] 1 SPEAKER_01']\n",
            "['[ 00:00:23.081 -->  00:00:25.135] 0 SPEAKER_00']\n",
            "['[ 00:00:25.848 -->  00:00:26.544] 1 SPEAKER_01', '[ 00:00:26.833 -->  00:00:29.414] 1 SPEAKER_01']\n",
            "['[ 00:00:30.263 -->  00:00:34.813] 0 SPEAKER_00', '[ 00:00:35.016 -->  00:00:35.033] 0 SPEAKER_00', '[ 00:00:35.050 -->  00:00:37.207] 0 SPEAKER_00', '[ 00:00:38.259 -->  00:00:41.264] 0 SPEAKER_00', '[ 00:00:41.706 -->  00:00:43.013] 0 SPEAKER_00']\n",
            "['[ 00:00:43.455 -->  00:00:43.573] 1 SPEAKER_01', '[ 00:00:44.219 -->  00:00:52.572] 1 SPEAKER_01', '[ 00:00:52.979 -->  00:00:56.986] 1 SPEAKER_01']\n",
            "['[ 00:00:57.461 -->  00:00:59.753] 0 SPEAKER_00', '[ 00:01:00.144 -->  00:01:00.297] 0 SPEAKER_00']\n",
            "['[ 00:01:00.551 -->  00:01:03.539] 1 SPEAKER_01', '[ 00:01:03.862 -->  00:01:06.561] 1 SPEAKER_01', '[ 00:01:06.884 -->  00:01:12.741] 1 SPEAKER_01']\n",
            "['[ 00:01:13.047 -->  00:01:17.342] 0 SPEAKER_00', '[ 00:01:18.174 -->  00:01:19.787] 0 SPEAKER_00']\n",
            "['[ 00:01:19.787 -->  00:01:19.940] 1 SPEAKER_01']\n",
            "['[ 00:01:19.940 -->  00:01:19.991] 0 SPEAKER_00']\n",
            "['[ 00:01:19.991 -->  00:01:20.704] 1 SPEAKER_01']\n",
            "['[ 00:01:21.502 -->  00:01:23.522] 0 SPEAKER_00', '[ 00:01:23.658 -->  00:01:24.303] 0 SPEAKER_00', '[ 00:01:24.643 -->  00:01:26.561] 0 SPEAKER_00', '[ 00:01:26.918 -->  00:01:28.446] 0 SPEAKER_00', '[ 00:01:28.667 -->  00:01:31.383] 0 SPEAKER_00']\n",
            "['[ 00:01:31.502 -->  00:01:31.723] 1 SPEAKER_01']\n",
            "['[ 00:01:31.723 -->  00:01:31.740] 0 SPEAKER_00', '[ 00:01:31.791 -->  00:01:31.960] 0 SPEAKER_00']\n",
            "['[ 00:01:32.640 -->  00:01:35.560] 1 SPEAKER_01', '[ 00:01:36.867 -->  00:01:36.918] 1 SPEAKER_01']\n",
            "['[ 00:01:36.918 -->  00:01:36.935] 0 SPEAKER_00']\n",
            "['[ 00:01:36.935 -->  00:01:37.563] 1 SPEAKER_01']\n",
            "['[ 00:01:37.563 -->  00:01:37.988] 0 SPEAKER_00']\n",
            "['[ 00:01:37.988 -->  00:01:38.022] 1 SPEAKER_01']\n",
            "['[ 00:01:38.022 -->  00:01:38.073] 0 SPEAKER_00']\n",
            "['[ 00:01:38.073 -->  00:01:38.140] 1 SPEAKER_01']\n",
            "['[ 00:01:38.140 -->  00:01:38.174] 0 SPEAKER_00']\n",
            "['[ 00:01:38.174 -->  00:01:38.242] 1 SPEAKER_01', '[ 00:01:38.616 -->  00:01:38.921] 1 SPEAKER_01']\n",
            "['[ 00:01:38.921 -->  00:01:39.006] 0 SPEAKER_00']\n",
            "['[ 00:01:39.006 -->  00:01:46.188] 1 SPEAKER_01', '[ 00:01:46.392 -->  00:01:49.125] 1 SPEAKER_01', '[ 00:01:49.448 -->  00:01:55.271] 1 SPEAKER_01', '[ 00:01:55.713 -->  00:02:01.451] 1 SPEAKER_01']\n",
            "['[ 00:02:01.502 -->  00:02:10.959] 0 SPEAKER_00', '[ 00:02:11.536 -->  00:02:16.256] 0 SPEAKER_00']\n",
            "['[ 00:02:16.256 -->  00:02:17.512] 1 SPEAKER_01', '[ 00:02:17.886 -->  00:02:18.616] 1 SPEAKER_01', '[ 00:02:19.465 -->  00:02:23.879] 1 SPEAKER_01', '[ 00:02:24.235 -->  00:02:26.069] 1 SPEAKER_01', '[ 00:02:26.409 -->  00:02:33.370] 1 SPEAKER_01', '[ 00:02:33.658 -->  00:02:37.665] 1 SPEAKER_01', '[ 00:02:37.988 -->  00:02:41.570] 1 SPEAKER_01', '[ 00:02:41.943 -->  00:02:44.966] 1 SPEAKER_01']\n",
            "['[ 00:02:45.254 -->  00:02:49.617] 0 SPEAKER_00']\n",
            "['[ 00:02:50.263 -->  00:02:58.463] 1 SPEAKER_01', '[ 00:02:58.887 -->  00:03:06.833] 1 SPEAKER_01']\n",
            "['[ 00:03:06.850 -->  00:03:07.920] 0 SPEAKER_00']\n",
            "['[ 00:03:07.920 -->  00:03:11.078] 1 SPEAKER_01', '[ 00:03:11.485 -->  00:03:18.989] 1 SPEAKER_01']\n",
            "['[ 00:03:18.989 -->  00:03:24.049] 0 SPEAKER_00']\n",
            "['[ 00:03:24.049 -->  00:03:55.101] 1 SPEAKER_01']\n",
            "['[ 00:03:55.984 -->  00:03:58.073] 0 SPEAKER_00']\n",
            "['[ 00:03:58.242 -->  00:04:04.219] 1 SPEAKER_01']\n",
            "['[ 00:04:04.575 -->  00:04:10.942] 0 SPEAKER_00']\n",
            "['[ 00:04:11.315 -->  00:04:27.020] 1 SPEAKER_01']\n",
            "['[ 00:04:28.395 -->  00:04:28.837] 0 SPEAKER_00', '[ 00:04:29.482 -->  00:04:30.908] 0 SPEAKER_00', '[ 00:04:31.078 -->  00:04:31.485] 0 SPEAKER_00', '[ 00:04:31.723 -->  00:04:33.302] 0 SPEAKER_00']\n",
            "['[ 00:04:34.134 -->  00:04:54.100] 1 SPEAKER_01', '[ 00:04:54.660 -->  00:04:56.035] 1 SPEAKER_01']\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "dzs = open('diarization.txt').read().splitlines()\n",
        "\n",
        "groups = []\n",
        "g = []\n",
        "lastend = 0\n",
        "\n",
        "for d in dzs:\n",
        "  if g and (g[0].split()[-1] != d.split()[-1]):      #same speaker\n",
        "    groups.append(g)\n",
        "    g = []\n",
        "\n",
        "  g.append(d)\n",
        "\n",
        "  end = re.findall('[0-9]+:[0-9]+:[0-9]+\\.[0-9]+', string=d)[1]\n",
        "  end = millisec(end)\n",
        "  if (lastend > end):       #segment engulfed by a previous segment\n",
        "    groups.append(g)\n",
        "    g = []\n",
        "  else:\n",
        "    lastend = end\n",
        "if g:\n",
        "  groups.append(g)\n",
        "print(*groups, sep='\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOuf8CuRQeZo"
      },
      "source": [
        "Save the audio part corresponding to each diarization group."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "dRQPUW4Mzvfn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "group 0: 16341--18225\n",
            "group 1: 17376--19804\n",
            "group 2: 20059--22707\n",
            "group 3: 23081--25135\n",
            "group 4: 25848--29414\n",
            "group 5: 30263--43013\n",
            "group 6: 43455--56986\n",
            "group 7: 57461--60297\n",
            "group 8: 60551--72741\n",
            "group 9: 73047--79787\n",
            "group 10: 79787--79940\n",
            "group 11: 79940--79991\n",
            "group 12: 79991--80704\n",
            "group 13: 81502--91383\n",
            "group 14: 91502--91723\n",
            "group 15: 91723--91960\n",
            "group 16: 92640--96918\n",
            "group 17: 96918--96935\n",
            "group 18: 96935--97563\n",
            "group 19: 97563--97988\n",
            "group 20: 97988--98021\n",
            "group 21: 98021--98073\n",
            "group 22: 98073--98140\n",
            "group 23: 98140--98174\n",
            "group 24: 98174--98920\n",
            "group 25: 98920--99006\n",
            "group 26: 99006--121451\n",
            "group 27: 121502--136256\n",
            "group 28: 136256--164966\n",
            "group 29: 165254--169617\n",
            "group 30: 170263--186833\n",
            "group 31: 186850--187920\n",
            "group 32: 187920--198989\n",
            "group 33: 198989--204049\n",
            "group 34: 204049--235101\n",
            "group 35: 235984--238073\n",
            "group 36: 238242--244219\n",
            "group 37: 244575--250942\n",
            "group 38: 251315--267020\n",
            "group 39: 268395--273302\n",
            "group 40: 274134--296034\n"
          ]
        }
      ],
      "source": [
        "audio = AudioSegment.from_wav(\"input_prep.wav\")\n",
        "gidx = -1\n",
        "for g in groups:\n",
        "  start = re.findall('[0-9]+:[0-9]+:[0-9]+\\.[0-9]+', string=g[0])[0]\n",
        "  end = re.findall('[0-9]+:[0-9]+:[0-9]+\\.[0-9]+', string=g[-1])[1]\n",
        "  start = millisec(start) #- spacermilli\n",
        "  end = millisec(end)  #- spacermilli\n",
        "  gidx += 1\n",
        "  audio[start:end].export(str(gidx) + '.wav', format='wav')\n",
        "  print(f\"group {gidx}: {start}--{end}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv2GYZCsLKBJ"
      },
      "source": [
        "Freeing up some memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cONumKWUjfus"
      },
      "outputs": [],
      "source": [
        "del   DEMO_FILE, pipeline, spacer,  audio, dz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdY4dfGUzPqS"
      },
      "source": [
        "## Whisper STT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "nyFnyRozzbqa"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = whisper.load_model('base', device = device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "fSSwlyqt0Xom"
      },
      "outputs": [],
      "source": [
        "# !export LC_ALL=\"en_US.UTF-8\"\n",
        "# !export LD_LIBRARY_PATH=\"/usr/lib64-nvidia\"\n",
        "# !export LIBRARY_PATH=\"/usr/local/cuda/lib64/stubs\"\n",
        "# !ldconfig /usr/lib64-nvidia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "1r8_ExWuzudf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 41/41 [00:49<00:00,  1.21s/it]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from tqdm import tqdm\n",
        "for i in tqdm(range(len(groups))):\n",
        "  audiof = str(i) + '.wav'\n",
        "  result = model.transcribe(audio=audiof, language='en', word_timestamps=True)#, initial_prompt=result.get('text', \"\"))\n",
        "  with open(str(i)+'.json', \"w\") as outfile:\n",
        "    json.dump(result, outfile, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "NLJ8VgVs0SvA"
      },
      "outputs": [],
      "source": [
        "speakers = {'SPEAKER_00':(speakers_[\"SPEAKER_00\"], '#e1ffc7', 'darkgreen'), 'SPEAKER_01':(speakers_[\"SPEAKER_01\"], 'white', 'darkorange') }\n",
        "def_boxclr = 'white'\n",
        "def_spkrclr = 'orange'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "xMPn3o1N5lB1"
      },
      "outputs": [],
      "source": [
        "if Source == 'Youtube':\n",
        "    preS = '<!DOCTYPE html>\\n<html lang=\"en\">\\n\\n<head>\\n\\t<meta charset=\"UTF-8\">\\n\\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\\n\\t<meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\\n\\t<title>' + \\\n",
        "video_title+ \\\n",
        "'</title>\\n\\t<style>\\n\\t\\tbody {\\n\\t\\t\\tfont-family: sans-serif;\\n\\t\\t\\tfont-size: 14px;\\n\\t\\t\\tcolor: #111;\\n\\t\\t\\tpadding: 0 0 1em 0;\\n\\t\\t\\tbackground-color: #efe7dd;\\n\\t\\t}\\n\\n\\t\\ttable {\\n\\t\\t\\tborder-spacing: 10px;\\n\\t\\t}\\n\\n\\t\\tth {\\n\\t\\t\\ttext-align: left;\\n\\t\\t}\\n\\n\\t\\t.lt {\\n\\t\\t\\tcolor: inherit;\\n\\t\\t\\ttext-decoration: inherit;\\n\\t\\t}\\n\\n\\t\\t.l {\\n\\t\\t\\tcolor: #050;\\n\\t\\t}\\n\\n\\t\\t.s {\\n\\t\\t\\tdisplay: inline-block;\\n\\t\\t}\\n\\n\\t\\t.c {\\n\\t\\t\\tdisplay: inline-block;\\n\\t\\t}\\n\\n\\t\\t.e {\\n\\t\\t\\t/*background-color: white; Changing background color */\\n\\t\\t\\tborder-radius: 10px;\\n\\t\\t\\t/* Making border radius */\\n\\t\\t\\twidth: 50%;\\n\\t\\t\\t/* Making auto-sizable width */\\n\\t\\t\\tpadding: 0 0 0 0;\\n\\t\\t\\t/* Making space around letters */\\n\\t\\t\\tfont-size: 14px;\\n\\t\\t\\t/* Changing font size */\\n\\t\\t\\tmargin-bottom: 0;\\n\\t\\t}\\n\\n\\t\\t.t {\\n\\t\\t\\tdisplay: inline-block;\\n\\t\\t}\\n\\n\\t\\t#player-div {\\n\\t\\t\\tposition: sticky;\\n\\t\\t\\ttop: 20px;\\n\\t\\t\\tfloat: right;\\n\\t\\t\\twidth: 40%\\n\\t\\t}\\n\\n\\t\\t#player {\\n\\t\\t\\taspect-ratio: 16 / 9;\\n\\t\\t\\twidth: 100%;\\n\\t\\t\\theight: auto;\\n\\n\\t\\t}\\n\\n\\t\\ta {\\n\\t\\t\\tdisplay: inline;\\n\\t\\t}\\n\\t</style>\\n\\t<script>\\n\\t\\tvar tag = document.createElement(\\'script\\');\\n\\t\\ttag.src = \"https://www.youtube.com/iframe_api\";\\n\\t\\tvar firstScriptTag = document.getElementsByTagName(\\'script\\')[0];\\n\\t\\tfirstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\\n\\t\\tvar player;\\n\\t\\tfunction onYouTubeIframeAPIReady() {\\n\\t\\t\\tplayer = new YT.Player(\\'player\\', {\\n\\t\\t\\t\\t//height: \\'210\\',\\n\\t\\t\\t\\t//width: \\'340\\',\\n\\t\\t\\t\\tvideoId: \\''+ \\\n",
        "video_id + \\\n",
        "'\\',\\n\\t\\t\\t});\\n\\n\\n\\n\\t\\t\\t// This is the source \"window\" that will emit the events.\\n\\t\\t\\tvar iframeWindow = player.getIframe().contentWindow;\\n\\t\\t\\tvar lastword = null;\\n\\n\\t\\t\\t// So we can compare against new updates.\\n\\t\\t\\tvar lastTimeUpdate = \"-1\";\\n\\n\\t\\t\\t// Listen to events triggered by postMessage,\\n\\t\\t\\t// this is how different windows in a browser\\n\\t\\t\\t// (such as a popup or iFrame) can communicate.\\n\\t\\t\\t// See: https://developer.mozilla.org/en-US/docs/Web/API/Window/postMessage\\n\\t\\t\\twindow.addEventListener(\"message\", function (event) {\\n\\t\\t\\t\\t// Check that the event was sent from the YouTube IFrame.\\n\\t\\t\\t\\tif (event.source === iframeWindow) {\\n\\t\\t\\t\\t\\tvar data = JSON.parse(event.data);\\n\\n\\t\\t\\t\\t\\t// The \"infoDelivery\" event is used by YT to transmit any\\n\\t\\t\\t\\t\\t// kind of information change in the player,\\n\\t\\t\\t\\t\\t// such as the current time or a playback quality change.\\n\\t\\t\\t\\t\\tif (\\n\\t\\t\\t\\t\\t\\tdata.event === \"infoDelivery\" &&\\n\\t\\t\\t\\t\\t\\tdata.info &&\\n\\t\\t\\t\\t\\t\\tdata.info.currentTime\\n\\t\\t\\t\\t\\t) {\\n\\t\\t\\t\\t\\t\\t// currentTime is emitted very frequently (milliseconds),\\n\\t\\t\\t\\t\\t\\t// but we only care about whole second changes.\\n\\t\\t\\t\\t\\t\\tvar ts = (data.info.currentTime).toFixed(1).toString();\\n\\t\\t\\t\\t\\t\\tts = (Math.round((data.info.currentTime) * 5) / 5).toFixed(1);\\n\\t\\t\\t\\t\\t\\tts = ts.toString();\\n\\t\\t\\t\\t\\t\\tconsole.log(ts)\\n\\t\\t\\t\\t\\t\\tif (ts !== lastTimeUpdate) {\\n\\t\\t\\t\\t\\t\\t\\tlastTimeUpdate = ts;\\n\\n\\t\\t\\t\\t\\t\\t\\t// It\\'s now up to you to format the time.\\n\\t\\t\\t\\t\\t\\t\\t//document.getElementById(\"time2\").innerHTML = time;\\n\\t\\t\\t\\t\\t\\t\\tword = document.getElementById(ts)\\n\\t\\t\\t\\t\\t\\t\\tif (word) {\\n\\t\\t\\t\\t\\t\\t\\t\\tif (lastword) {\\n\\t\\t\\t\\t\\t\\t\\t\\t\\tlastword.style.fontWeight = \\'normal\\';\\n\\t\\t\\t\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t\\t\\t\\t\\tlastword = word;\\n\\t\\t\\t\\t\\t\\t\\t\\t//word.style.textDecoration = \\'underline\\';\\n\\t\\t\\t\\t\\t\\t\\t\\tword.style.fontWeight = \\'bold\\';\\n\\n\\t\\t\\t\\t\\t\\t\\t\\tlet toggle = document.getElementById(\"autoscroll\");\\n\\t\\t\\t\\t\\t\\t\\t\\tif (toggle.checked) {\\n\\t\\t\\t\\t\\t\\t\\t\\t\\tlet position = word.offsetTop - 20;\\n\\t\\t\\t\\t\\t\\t\\t\\t\\twindow.scrollTo({\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\ttop: position,\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tbehavior: \\'smooth\\'\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t});\\n\\t\\t\\t\\t\\t\\t\\t\\t}\\n\\n\\t\\t\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t}\\n\\t\\t\\t})\\n\\t\\t}\\n\\t\\tfunction jumptoTime(timepoint, id) {\\n\\t\\t\\tevent.preventDefault();\\n\\t\\t\\thistory.pushState(null, null, \"#\" + id);\\n\\t\\t\\tplayer.seekTo(timepoint);\\n\\t\\t\\tplayer.playVideo();\\n\\t\\t}\\n\\t</script>\\n</head>\\n\\n<body>\\n\\t<h2>'  + \\\n",
        "video_title + \\\n",
        "'</h2>\\n\\t<i>Click on a part of the transcription, to jump to its video, and get an anchor to it in the address\\n\\t\\tbar<br><br></i>\\n\\t<div id=\"player-div\">\\n\\t\\t<div id=\"player\"></div>\\n\\t\\t<div><label for=\"autoscroll\">auto-scroll: </label>\\n\\t\\t\\t<input type=\"checkbox\" id=\"autoscroll\" checked>\\n\\t\\t</div>\\n\\t</div>\\n  '\n",
        "else:\n",
        "    preS = '\\n<!DOCTYPE html>\\n<html lang=\"en\">\\n\\n<head>\\n\\t<meta charset=\"UTF-8\">\\n\\t<meta name=\"viewport\" content=\"whtmlidth=device-width, initial-scale=1.0\">\\n\\t<meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\\n\\t<title>' + \\\n",
        "    audio_title+ \\\n",
        "    '</title>\\n\\t<style>\\n\\t\\tbody {\\n\\t\\t\\tfont-family: sans-serif;\\n\\t\\t\\tfont-size: 14px;\\n\\t\\t\\tcolor: #111;\\n\\t\\t\\tpadding: 0 0 1em 0;\\n\\t\\t\\tbackground-color: #efe7dd;\\n\\t\\t}\\n\\n\\t\\ttable {\\n\\t\\t\\tborder-spacing: 10px;\\n\\t\\t}\\n\\n\\t\\tth {\\n\\t\\t\\ttext-align: left;\\n\\t\\t}\\n\\n\\t\\t.lt {\\n\\t\\t\\tcolor: inherit;\\n\\t\\t\\ttext-decoration: inherit;\\n\\t\\t}\\n\\n\\t\\t.l {\\n\\t\\t\\tcolor: #050;\\n\\t\\t}\\n\\n\\t\\t.s {\\n\\t\\t\\tdisplay: inline-block;\\n\\t\\t}\\n\\n\\t\\t.c {\\n\\t\\t\\tdisplay: inline-block;\\n\\t\\t}\\n\\n\\t\\t.e {\\n\\t\\t\\t/*background-color: white; Changing background color */\\n\\t\\t\\tborder-radius: 10px;\\n\\t\\t\\t/* Making border radius */\\n\\t\\t\\twidth: 50%;\\n\\t\\t\\t/* Making auto-sizable width */\\n\\t\\t\\tpadding: 0 0 0 0;\\n\\t\\t\\t/* Making space around letters */\\n\\t\\t\\tfont-size: 14px;\\n\\t\\t\\t/* Changing font size */\\n\\t\\t\\tmargin-bottom: 0;\\n\\t\\t}\\n\\n\\t\\t.t {\\n\\t\\t\\tdisplay: inline-block;\\n\\t\\t}\\n\\n\\t\\t#player-div {\\n\\t\\t\\tposition: sticky;\\n\\t\\t\\ttop: 20px;\\n\\t\\t\\tfloat: right;\\n\\t\\t\\twidth: 40%\\n\\t\\t}\\n\\n\\t\\t#player {\\n\\t\\t\\taspect-ratio: 16 / 9;\\n\\t\\t\\twidth: 100%;\\n\\t\\t\\theight: auto;\\n\\t\\t}\\n\\n\\t\\ta {\\n\\t\\t\\tdisplay: inline;\\n\\t\\t}\\n\\t</style>';\n",
        "    preS += '\\n\\t<script>\\n\\twindow.onload = function () {\\n\\t\\t\\tvar player = document.getElementById(\"audio_player\");\\n\\t\\t\\tvar player;\\n\\t\\t\\tvar lastword = null;\\n\\n\\t\\t\\t// So we can compare against new updates.\\n\\t\\t\\tvar lastTimeUpdate = \"-1\";\\n\\n\\t\\t\\tsetInterval(function () {\\n\\t\\t\\t\\t// currentTime is checked very frequently (1 millisecond),\\n\\t\\t\\t\\t// but we only care about whole second changes.\\n\\t\\t\\t\\tvar ts = (player.currentTime).toFixed(1).toString();\\n\\t\\t\\t\\tts = (Math.round((player.currentTime) * 5) / 5).toFixed(1);\\n\\t\\t\\t\\tts = ts.toString();\\n\\t\\t\\t\\tconsole.log(ts);\\n\\t\\t\\t\\tif (ts !== lastTimeUpdate) {\\n\\t\\t\\t\\t\\tlastTimeUpdate = ts;\\n\\n\\t\\t\\t\\t\\t// Its now up to you to format the time.\\n\\t\\t\\t\\t\\tword = document.getElementById(ts)\\n\\t\\t\\t\\t\\tif (word) {\\n\\t\\t\\t\\t\\t\\tif (lastword) {\\n\\t\\t\\t\\t\\t\\t\\tlastword.style.fontWeight = \"normal\";\\n\\t\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t\\t\\tlastword = word;\\n\\t\\t\\t\\t\\t\\t//word.style.textDecoration = \"underline\";\\n\\t\\t\\t\\t\\t\\tword.style.fontWeight = \"bold\";\\n\\n\\t\\t\\t\\t\\t\\tlet toggle = document.getElementById(\"autoscroll\");\\n\\t\\t\\t\\t\\t\\tif (toggle.checked) {\\n\\t\\t\\t\\t\\t\\t\\tlet position = word.offsetTop - 20;\\n\\t\\t\\t\\t\\t\\t\\twindow.scrollTo({\\n\\t\\t\\t\\t\\t\\t\\t\\ttop: position,\\n\\t\\t\\t\\t\\t\\t\\t\\tbehavior: \"smooth\"\\n\\t\\t\\t\\t\\t\\t\\t});\\n\\t\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t}\\n\\t\\t\\t}, 0.1);\\n\\t\\t}\\n\\n\\t\\tfunction jumptoTime(timepoint, id) {\\n\\t\\t\\tvar player = document.getElementById(\"audio_player\");\\n\\t\\t\\thistory.pushState(null, null, \"#\" + id);\\n\\t\\t\\tplayer.pause();\\n\\t\\t\\tplayer.currentTime = timepoint;\\n\\t\\t\\tplayer.play();\\n\\t\\t}\\n\\t\\t</script>\\n\\t</head>';\n",
        "    preS += '\\n\\n<body>\\n\\t<h2>' + audio_title + '</h2>\\n\\t<i>Click on a part of the transcription, to jump to its portion of audio, and get an anchor to it in the address\\n\\t\\tbar<br><br></i>\\n\\t<div id=\"player-div\">\\n\\t\\t<div id=\"player\">\\n\\t\\t\\t<audio controls=\"controls\" id=\"audio_player\">\\n\\t\\t\\t\\t<source src=\"input.wav\" />\\n\\t\\t\\t</audio>\\n\\t\\t</div>\\n\\t\\t<div><label for=\"autoscroll\">auto-scroll: </label>\\n\\t\\t\\t<input type=\"checkbox\" id=\"autoscroll\" checked>\\n\\t\\t</div>\\n\\t</div>\\n';\n",
        "\n",
        "postS = '\\t</body>\\n</html>'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "K9SP3WlZ5pma"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "captions saved to transcription.txt:\n",
            "\n",
            "[Doctor]:  Hi, Mr. Jones. How are you?\n",
            "[Patient]:  How are you? I'm good, Dr. Svet, I'm ready to see you.\n",
            "[Doctor]:  Thanks to see you again. What brings you back?\n",
            "[Patient]:  Uh, well my back's been hurting again.\n",
            "[Doctor]:  I've seen you a number of times for this haven't I?\n",
            "[Patient]:  Well, ever since I got hurt on the job three years ago, it's something that just keeps coming back. It'll be fine for a while, and then I'll end down, or I'll move in a weird way, and then, boom, it'll just go out again.\n",
            "[Doctor]:  And unfortunately that can happen. And I do have quite a few patients who get reoccurring episodes of back pain. Have you been keeping up with the therapy that we had you on before?\n",
            "[Patient]:  which the pills.\n",
            "[Doctor]:  Actually, I was talking about the physical therapy that we had you doing. The pills were only meant for a short term because they don't actually prevent the back pain from coming back.\n",
            "[Patient]:  So yeah, once my back started feeling better, I was happy not to go to the therapist anymore.\n",
            "[Doctor]:  Why was that?\n",
            "[Patient]:  was starting to become kind of a hassle, you know, with my work schedule and the cost was an issue, but I was able to get back to work so, and I could use the money.\n",
            "[Doctor]:  Do you think the physical therapy was helping? Yeah, it would be smart.\n",
            "[Patient]:  you\n",
            "[Doctor]:  First, I see physical therapy is a bit slower than medications, but the point is to build up the core muscles in your back and your abdomen. Physical therapy is also less invasive than medications, so that's why we had you doing the therapy. But you mentioned that cost was getting to be a real issue for you. Can you tell me more about that?\n",
            "[Patient]:  Well, the insurance I had only covered a certain number of sessions, and then they moved my therapy office because they were trying to work out my schedule at work, but that was really far away, and then I had to do with parking, and it just started to get really expensive.\n",
            "[Doctor]:  God it and I understand. So for now I'd like you to try using a heating pad for your back pain. So that should help in the short term. Our goal is to get your back pain under better control without creating additional problems for you like cost. Let's talk about some different options and the pros and cons of each. So the physical therapy is actually really good for your back pain, but there are other things we can be doing to help.\n",
            "[Patient]:  Yes, I definitely don't need to lose any more time at work and just lie around a house all day.\n",
            "[Doctor]:  Okay, well there are some alternative therapies like yoga or Tai Chi classes or meditation therapies that might be able to help. And they might also be closer to you and be less expensive. Would that be something you'd be interested in?\n",
            "[Patient]:  sure that'd be great.\n",
            "[Doctor]:  Let's talk about some of the other costs of your care. In the past, we had you on some tram at all because the physical therapy alone wasn't working.\n",
            "[Patient]:  Yeah, that medicine was working really well, but again the cost of it got really expensive.\n",
            "[Doctor]:  Yeah, yeah. So that is something in the future we could order, something like a generic medication. And then there are also resources for people to look up the cheapest cost of their medications. But for now, I'd like to stick with the non-prescription medications. And if we can have you go to yoga or Tai Chi classes, like I mentioned, that could alleviate the need for ordering prescriptions.\n",
            "[Patient]:  Okay, yeah, that sounds good. Okay.\n",
            "[Doctor]:  Great, great. Are there any other costs that are a problem for you and your care?\n",
            "[Patient]:  Well my insurance isn't going down, but that seems to be the case for everybody that I talk to, but I should be able to make it work. Yeah.\n",
            "[Doctor]:  And fortunately that is an issue for a lot of people, but I would encourage you during open season to look at your different insurance options to see which plan is more cost effective for you.\n",
            "[Patient]:  Okay. Yeah, that sounds great. Great. Well, I appreciate you talking to me today.\n",
            "[Doctor]:  Yeah, I'm glad you were able to come in. What I'll do is I'll have my office team research, the different things that you and I talked about today. And then let's set a time, early next week, say Tuesday, where we can talk over the phone about what we were able to come up with for you and see if those would work for you. Okay, great. Great.\n",
            "\n",
            "captions saved to transcription.html:\n"
          ]
        }
      ],
      "source": [
        "#import webvtt\n",
        "import json\n",
        "from datetime import timedelta\n",
        "\n",
        "def timeStr(t):\n",
        "  return '{0:02d}:{1:02d}:{2:06.2f}'.format(round(t // 3600),\n",
        "                                                round(t % 3600 // 60),\n",
        "                                                t % 60)\n",
        "\n",
        "html = list(preS)\n",
        "txt = list(\"\")\n",
        "gidx = -1\n",
        "for g in groups:\n",
        "  shift = re.findall('[0-9]+:[0-9]+:[0-9]+\\.[0-9]+', string=g[0])[0]\n",
        "  shift = millisec(shift) - spacermilli #the start time in the original video\n",
        "  shift=max(shift, 0)\n",
        "\n",
        "  gidx += 1\n",
        "\n",
        "  captions = json.load(open(str(gidx) + '.json'))['segments']\n",
        "\n",
        "  if captions:\n",
        "    speaker = g[0].split()[-1]\n",
        "    boxclr = def_boxclr\n",
        "    spkrclr = def_spkrclr\n",
        "    if speaker in speakers:\n",
        "      speaker, boxclr, spkrclr = speakers[speaker]\n",
        "\n",
        "    html.append(f'<div class=\"e\" style=\"background-color: {boxclr}\">\\n');\n",
        "    html.append('<p  style=\"margin:0;padding: 5px 10px 10px 10px;word-wrap:normal;white-space:normal;\">\\n')\n",
        "    html.append(f'<span style=\"color:{spkrclr};font-weight: bold;\">{speaker}</span><br>\\n\\t\\t\\t\\t')\n",
        "\n",
        "    for c in captions:\n",
        "      start = shift + c['start'] * 1000.0\n",
        "      start = start / 1000.0   #time resolution ot youtube is Second.\n",
        "      end = (shift + c['end'] * 1000.0) / 1000.0\n",
        "      # txt.append(f'[{timeStr(start)} --> {timeStr(end)}] [{speaker}] {c[\"text\"]}\\n')\n",
        "      if txt and txt[-1].split(\":\")[0].strip() == f\"[{speaker}]\":\n",
        "        # print(txt[-1].split(\":\")[0].strip(), f\"[{speaker}]\")\n",
        "        txt[-1]+=f'{c[\"text\"]}'\n",
        "      else:\n",
        "        txt.append(f'\\n[{speaker}]: {c[\"text\"]}')\n",
        "\n",
        "      for i, w in enumerate(c['words']):\n",
        "        if w == \"\":\n",
        "           continue\n",
        "        start = (shift + w['start']*1000.0) / 1000.0\n",
        "        #end = (shift + w['end']) / 1000.0   #time resolution ot youtube is Second.\n",
        "        html.append(f'<a href=\"#{timeStr(start)}\" id=\"{\"{:.1f}\".format(round(start*5)/5)}\" class=\"lt\" onclick=\"jumptoTime({int(start)}, this.id)\">{w[\"word\"]}</a><!--\\n\\t\\t\\t\\t-->')\n",
        "    #html.append('\\n')\n",
        "    html.append('</p>\\n')\n",
        "    html.append(f'</div>\\n')\n",
        "\n",
        "html.append(postS)\n",
        "\n",
        "\n",
        "with open(f\"transcription.txt\", \"w\", encoding='utf-8') as file:\n",
        "  s = \"\".join(txt)\n",
        "  file.write(s)\n",
        "  print('captions saved to transcription.txt:')\n",
        "  print(s+'\\n')\n",
        "\n",
        "with open(f\"transcription.html\", \"w\", encoding='utf-8') as file:    #TODO: proper html embed tag when video/audio from file\n",
        "  s = \"\".join(html)\n",
        "  file.write(s)\n",
        "  print('captions saved to transcription.html:')\n",
        "  # print(s+'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCTetJIJ5tWX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
